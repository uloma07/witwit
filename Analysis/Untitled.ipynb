{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "725a2643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADMIN', 'ISO_A3', 'ISO_A2', 'geometry']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import json\n",
    "from shapely.geometry import mapping, shape\n",
    "from shapely.prepared import prep\n",
    "from shapely.geometry import Point\n",
    "\n",
    "data = gpd.read_file(r'C:\\Users\\ogechi\\OneDrive - University of Glasgow\\bottle\\countries.geojson')\n",
    "df = pd.read_json(r'C:\\Users\\ogechi\\OneDrive - University of Glasgow\\bottle\\processed_image_data.indoor.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4918ba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['country_bounds'] = data.apply(lambda row: prep(shape(row['geometry'])), axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7b6d077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADMIN</th>\n",
       "      <th>ISO_A3</th>\n",
       "      <th>ISO_A2</th>\n",
       "      <th>geometry</th>\n",
       "      <th>country_bounds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aruba</td>\n",
       "      <td>ABW</td>\n",
       "      <td>AW</td>\n",
       "      <td>MULTIPOLYGON (((-69.99694 12.57758, -69.93639 ...</td>\n",
       "      <td>&lt;shapely.prepared.PreparedGeometry object at 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>AF</td>\n",
       "      <td>MULTIPOLYGON (((71.04980 38.40866, 71.05714 38...</td>\n",
       "      <td>&lt;shapely.prepared.PreparedGeometry object at 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Angola</td>\n",
       "      <td>AGO</td>\n",
       "      <td>AO</td>\n",
       "      <td>MULTIPOLYGON (((11.73752 -16.69258, 11.73851 -...</td>\n",
       "      <td>&lt;shapely.prepared.PreparedGeometry object at 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anguilla</td>\n",
       "      <td>AIA</td>\n",
       "      <td>AI</td>\n",
       "      <td>MULTIPOLYGON (((-63.03767 18.21296, -63.09952 ...</td>\n",
       "      <td>&lt;shapely.prepared.PreparedGeometry object at 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albania</td>\n",
       "      <td>ALB</td>\n",
       "      <td>AL</td>\n",
       "      <td>MULTIPOLYGON (((19.74777 42.57890, 19.74601 42...</td>\n",
       "      <td>&lt;shapely.prepared.PreparedGeometry object at 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ADMIN ISO_A3 ISO_A2  \\\n",
       "0        Aruba    ABW     AW   \n",
       "1  Afghanistan    AFG     AF   \n",
       "2       Angola    AGO     AO   \n",
       "3     Anguilla    AIA     AI   \n",
       "4      Albania    ALB     AL   \n",
       "\n",
       "                                            geometry  \\\n",
       "0  MULTIPOLYGON (((-69.99694 12.57758, -69.93639 ...   \n",
       "1  MULTIPOLYGON (((71.04980 38.40866, 71.05714 38...   \n",
       "2  MULTIPOLYGON (((11.73752 -16.69258, 11.73851 -...   \n",
       "3  MULTIPOLYGON (((-63.03767 18.21296, -63.09952 ...   \n",
       "4  MULTIPOLYGON (((19.74777 42.57890, 19.74601 42...   \n",
       "\n",
       "                                      country_bounds  \n",
       "0  <shapely.prepared.PreparedGeometry object at 0...  \n",
       "1  <shapely.prepared.PreparedGeometry object at 0...  \n",
       "2  <shapely.prepared.PreparedGeometry object at 0...  \n",
       "3  <shapely.prepared.PreparedGeometry object at 0...  \n",
       "4  <shapely.prepared.PreparedGeometry object at 0...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dba52c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country(lon, lat):\n",
    "    if pd.isna(lon) or pd.isna(lat):\n",
    "        return \"\"\n",
    "    point = Point(lon, lat)\n",
    "    for i, row in data.iterrows():\n",
    "        geom = row['country_bounds']\n",
    "        if geom.contains(point):\n",
    "            return row['ADMIN']\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "df['country_label'] = df.apply(lambda row: get_country(row['longitude'], row['latitude']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8e9ed93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>license</th>\n",
       "      <th>date_upload</th>\n",
       "      <th>date_taken</th>\n",
       "      <th>owner_name</th>\n",
       "      <th>original_format</th>\n",
       "      <th>last_update</th>\n",
       "      <th>latitude</th>\n",
       "      <th>...</th>\n",
       "      <th>photoid</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>page_url</th>\n",
       "      <th>licenseurl</th>\n",
       "      <th>isindoor</th>\n",
       "      <th>category</th>\n",
       "      <th>page_source</th>\n",
       "      <th>address</th>\n",
       "      <th>type</th>\n",
       "      <th>country_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'$oid': '66031c7b2008c048c986ec6b'}</td>\n",
       "      <td>20121227_IMG_2406</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>1.359064e+09</td>\n",
       "      <td>2012-12-27 11:35:01</td>\n",
       "      <td>54177777@N00</td>\n",
       "      <td>jpg</td>\n",
       "      <td>1359064484</td>\n",
       "      <td>35.662359</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'$oid': '66031c7b2008c048c986ec6c'}</td>\n",
       "      <td>20121227_IMG_2405</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>1.359064e+09</td>\n",
       "      <td>2012-12-27 11:34:08</td>\n",
       "      <td>54177777@N00</td>\n",
       "      <td>jpg</td>\n",
       "      <td>1359064484</td>\n",
       "      <td>35.662359</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'$oid': '66031c7b2008c048c986ec6d'}</td>\n",
       "      <td>20121227_IMG_2404</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>1.359064e+09</td>\n",
       "      <td>2012-12-27 11:34:02</td>\n",
       "      <td>54177777@N00</td>\n",
       "      <td>jpg</td>\n",
       "      <td>1359064483</td>\n",
       "      <td>35.662359</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'$oid': '66031c7b2008c048c986ec6e'}</td>\n",
       "      <td>20121227_IMG_2399</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>1.359064e+09</td>\n",
       "      <td>2012-12-27 11:31:54</td>\n",
       "      <td>54177777@N00</td>\n",
       "      <td>jpg</td>\n",
       "      <td>1359064483</td>\n",
       "      <td>35.662359</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'$oid': '66031c7b2008c048c986ec6f'}</td>\n",
       "      <td>20121227_IMG_2398</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>1.359064e+09</td>\n",
       "      <td>2012-12-27 11:31:34</td>\n",
       "      <td>54177777@N00</td>\n",
       "      <td>jpg</td>\n",
       "      <td>1359064483</td>\n",
       "      <td>35.662359</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Japan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    _id              title description  \\\n",
       "0  {'$oid': '66031c7b2008c048c986ec6b'}  20121227_IMG_2406               \n",
       "1  {'$oid': '66031c7b2008c048c986ec6c'}  20121227_IMG_2405               \n",
       "2  {'$oid': '66031c7b2008c048c986ec6d'}  20121227_IMG_2404               \n",
       "3  {'$oid': '66031c7b2008c048c986ec6e'}  20121227_IMG_2399               \n",
       "4  {'$oid': '66031c7b2008c048c986ec6f'}  20121227_IMG_2398               \n",
       "\n",
       "  license   date_upload           date_taken    owner_name original_format  \\\n",
       "0       4  1.359064e+09  2012-12-27 11:35:01  54177777@N00             jpg   \n",
       "1       4  1.359064e+09  2012-12-27 11:34:08  54177777@N00             jpg   \n",
       "2       4  1.359064e+09  2012-12-27 11:34:02  54177777@N00             jpg   \n",
       "3       4  1.359064e+09  2012-12-27 11:31:54  54177777@N00             jpg   \n",
       "4       4  1.359064e+09  2012-12-27 11:31:34  54177777@N00             jpg   \n",
       "\n",
       "  last_update   latitude  ...  photoid accuracy page_url licenseurl isindoor  \\\n",
       "0  1359064484  35.662359  ...      NaN      NaN      NaN        NaN      NaN   \n",
       "1  1359064484  35.662359  ...      NaN      NaN      NaN        NaN      NaN   \n",
       "2  1359064483  35.662359  ...      NaN      NaN      NaN        NaN      NaN   \n",
       "3  1359064483  35.662359  ...      NaN      NaN      NaN        NaN      NaN   \n",
       "4  1359064483  35.662359  ...      NaN      NaN      NaN        NaN      NaN   \n",
       "\n",
       "   category  page_source  address type country_label  \n",
       "0       NaN          NaN      NaN  NaN         Japan  \n",
       "1       NaN          NaN      NaN  NaN         Japan  \n",
       "2       NaN          NaN      NaN  NaN         Japan  \n",
       "3       NaN          NaN      NaN  NaN         Japan  \n",
       "4       NaN          NaN      NaN  NaN         Japan  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc277832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv('updated_dataframe.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de83dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Read the data into a pandas DataFrame\n",
    "df = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Optimize the code by grouping the data by country_name and counting the occurrences\n",
    "country_counts = df.groupby('country_name').size().reset_index(name='counts')\n",
    "\n",
    "# Create the choropleth map\n",
    "fig = px.choropleth(country_counts,\n",
    "                    locations='country_name',\n",
    "                    color='counts',\n",
    "                    hover_name='country_name',\n",
    "                    color_continuous_scale='Plasma',\n",
    "                    projection='natural earth')\n",
    "\n",
    "# Update the layout\n",
    "fig.update_layout(\n",
    "    title='Number of Data Points per Country',\n",
    "    geo=dict(\n",
    "        showframe=False,\n",
    "        showcoastlines=False,\n",
    "        projection_type='equirectangular'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Show the map\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084baee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8018e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Load your dataframes\n",
    "df = pd.read_json(r'C:\\Users\\ogechi\\OneDrive - University of Glasgow\\bottle\\processed_image_data.indoor.json')\n",
    "data = gpd.read_file(r'C:\\Users\\ogechi\\OneDrive - University of Glasgow\\bottle\\countries.geojson')  # Ensure this file contains the necessary columns and geometries.\n",
    "data['country_bounds'] = data.apply(lambda row: prep(shape(row['geometry'])), axis=1)\n",
    "# Ensure 'data' has a proper GeoDataFrame setup with prepared geometries\n",
    "data['geom'] = data['country_bounds'].apply(lambda g: g.geom)  # Convert PreparedGeometry to usual Geometry if needed.\n",
    "countries_gdf = gpd.GeoDataFrame(data, geometry='geom')\n",
    "\n",
    "# Convert df to a GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.longitude, df.latitude), crs=\"EPSG:4326\")\n",
    "\n",
    "# Spatial join between points and countries\n",
    "result = gpd.sjoin(gdf, countries_gdf, how=\"left\", op='within')\n",
    "\n",
    "# Drop the unnecessary geometry column if no longer needed\n",
    "result = result.drop(columns=['geometry', 'index_right'])\n",
    "\n",
    "# Map the 'ADMIN' column from countries to your dataframe\n",
    "df['country_label'] = result['ADMIN']\n",
    "\n",
    "# Save or use df as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f37332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae06063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5908cdb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1fe748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa3ef9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_json(r'C:\\Users\\ogechi\\OneDrive - University of Glasgow\\bottle\\processed_image_data.indoor.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47526db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width Summary:\n",
      "count    320720.000000\n",
      "mean       3270.408525\n",
      "std        1602.419681\n",
      "min          71.000000\n",
      "25%        2048.000000\n",
      "50%        3264.000000\n",
      "75%        4032.000000\n",
      "max       34755.000000\n",
      "Name: width, dtype: float64\n",
      "\n",
      "Height Summary:\n",
      "count    320720.000000\n",
      "mean       2608.254721\n",
      "std        1244.514887\n",
      "min          54.000000\n",
      "25%        1836.000000\n",
      "50%        2591.000000\n",
      "75%        3240.000000\n",
      "max       19600.000000\n",
      "Name: height, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "summary_width = data['width'].describe()\n",
    "summary_height = data['height'].describe()\n",
    "\n",
    "print(\"Width Summary:\")\n",
    "print(summary_width)\n",
    "print(\"\\nHeight Summary:\")\n",
    "print(summary_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88d7b65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Common Dimensions:\n",
      "        width  height  count\n",
      "27795  3264.0  2448.0  32142\n",
      "37043  4032.0  3024.0  16060\n",
      "36412  4000.0  3000.0  10520\n",
      "42787  5312.0  2988.0   8957\n",
      "13782  2048.0  1365.0   6750\n",
      "42482  5184.0  3456.0   5938\n",
      "44711  6000.0  4000.0   5901\n",
      "32423  3648.0  2736.0   5387\n",
      "2068    640.0   640.0   4393\n",
      "24810  3024.0  4032.0   4384\n"
     ]
    }
   ],
   "source": [
    "# Combine width and height into a tuple and count occurrences\n",
    "common_dimensions = data.groupby(['width', 'height']).size().reset_index(name='count')\n",
    "common_dimensions = common_dimensions.sort_values(by='count', ascending=False)\n",
    "\n",
    "print(\"Most Common Dimensions:\")\n",
    "print(common_dimensions.head(10))  # Display top 10 most common dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "751b6c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect Ratio Summary:\n",
      "count    320720.000000\n",
      "mean          1.288868\n",
      "std           0.366547\n",
      "min           0.125151\n",
      "25%           1.000000\n",
      "50%           1.333333\n",
      "75%           1.500000\n",
      "max          15.000000\n",
      "Name: aspect_ratio, dtype: float64\n",
      "\n",
      "Common Aspect Ratios:\n",
      "1.333333    99612\n",
      "1.500000    30503\n",
      "1.777778    24297\n",
      "0.750000    20655\n",
      "1.000000    20284\n",
      "0.666667    10093\n",
      "1.500366     6759\n",
      "1.499268     6141\n",
      "1.338843     3171\n",
      "1.493827     3047\n",
      "Name: aspect_ratio, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate aspect ratios\n",
    "data['aspect_ratio'] = data['width'] / data['height']\n",
    "\n",
    "# Summary of aspect ratios\n",
    "aspect_ratio_summary = data['aspect_ratio'].describe()\n",
    "\n",
    "print(\"Aspect Ratio Summary:\")\n",
    "print(aspect_ratio_summary)\n",
    "\n",
    "# Frequency of common aspect ratios\n",
    "common_aspect_ratios = data['aspect_ratio'].value_counts().head(10)\n",
    "print(\"\\nCommon Aspect Ratios:\")\n",
    "print(common_aspect_ratios)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2abb84dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting 0001-01-01 12:12:12.0: Out of bounds nanosecond timestamp: 1-01-01 12:12:12\n",
      "Error converting null: Unknown string format: null\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ogechi\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py:1189: PerformanceWarning: Adding/subtracting object-dtype array to DatetimeArray not vectorized.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'Timestamp' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m summary_update \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast_update\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39magg([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Calculate time intervals\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupload_to_taken\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate_taken\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate_upload\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     31\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast_update_to_now\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimestamp(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnow\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast_update\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Output summary statistics\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\ops\\common.py:70\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     68\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\arraylike.py:108\u001b[0m, in \u001b[0;36mOpsMixin.__sub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sub__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\series.py:5639\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   5637\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[0;32m   5638\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39malign_method_SERIES(\u001b[38;5;28mself\u001b[39m, other)\n\u001b[1;32m-> 5639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexOpsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\base.py:1295\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1292\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m ensure_wrapped_if_datetimelike(rvalues)\n\u001b[0;32m   1294\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1295\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(result, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:216\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;66;03m# NB: We assume that extract_array and ensure_wrapped_if_datetimelike\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;66;03m#  have already been called on `left` and `right`,\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;66;03m#  and `maybe_prepare_scalar_for_op` has already been called on `right`\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;66;03m# We need to special-case datetime64/timedelta64 dtypes (e.g. because numpy\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;66;03m# casts integer dtypes to timedelta64 when operating with timedelta64 - GH#22390)\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    210\u001b[0m     should_extension_dispatch(left, right)\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(right, (Timedelta, BaseOffset, Timestamp))\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# Timedelta/Timestamp and other custom scalars are included in the check\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# because numexpr will fail on it, see GH#31457\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# TODO we should handle EAs consistently and move this check before the if/else\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# (https://github.com/pandas-dev/pandas/issues/41165)\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     _bool_arith_check(op, left, right)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\ops\\common.py:70\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     68\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py:1337\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin.__sub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   1334\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_timedelta_arraylike(\u001b[38;5;241m-\u001b[39mother)\n\u001b[0;32m   1335\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_object_dtype(other_dtype):\n\u001b[0;32m   1336\u001b[0m     \u001b[38;5;66;03m# e.g. Array/Index of DateOffset objects\u001b[39;00m\n\u001b[1;32m-> 1337\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_addsub_object_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1338\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_datetime64_dtype(other_dtype) \u001b[38;5;129;01mor\u001b[39;00m is_datetime64tz_dtype(other_dtype):\n\u001b[0;32m   1339\u001b[0m     \u001b[38;5;66;03m# DatetimeIndex, ndarray[datetime64]\u001b[39;00m\n\u001b[0;32m   1340\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sub_datetime_arraylike(other)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py:1201\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin._addsub_object_array\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m   1199\u001b[0m     \u001b[38;5;66;03m# filter out warnings about Timestamp.freq\u001b[39;00m\n\u001b[0;32m   1200\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[1;32m-> 1201\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mO\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1203\u001b[0m result \u001b[38;5;241m=\u001b[39m pd_array(res_values\u001b[38;5;241m.\u001b[39mravel())\n\u001b[0;32m   1204\u001b[0m \u001b[38;5;66;03m# error: Item \"ExtensionArray\" of \"Union[Any, ExtensionArray]\" has no attribute\u001b[39;00m\n\u001b[0;32m   1205\u001b[0m \u001b[38;5;66;03m# \"reshape\"\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'Timestamp' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "def convert_dates(date_item):\n",
    "    # Check the type of the date_item\n",
    "    if isinstance(date_item, pd.Timestamp):\n",
    "        # Already a Timestamp, return as is\n",
    "        return date_item\n",
    "    try:\n",
    "        # Assume it's a string and check if it's all digits (Unix timestamp)\n",
    "        if isinstance(date_item, str) and date_item.isdigit():\n",
    "            # Convert Unix timestamp to datetime\n",
    "            return pd.to_datetime(date_item, unit='s')\n",
    "        elif isinstance(date_item, str):\n",
    "            # Convert standard datetime strings\n",
    "            return pd.to_datetime(date_item)\n",
    "    except Exception as e:\n",
    "        # Handle exceptions that might be raised during conversion\n",
    "        print(f\"Error converting {date_item}: {e}\")\n",
    "        return pd.NaT  # Return NaT (Not a Time) for unconvertible formats\n",
    "\n",
    "# Apply the conversion function to each date column\n",
    "data['date_upload'] = data['date_upload'].apply(convert_dates)\n",
    "data['date_taken'] = data['date_taken'].apply(convert_dates)\n",
    "data['last_update'] = data['last_update'].apply(convert_dates)\n",
    "\n",
    "# Statistical Summary\n",
    "summary_upload = data['date_upload'].agg(['min', 'max'])\n",
    "summary_taken = data['date_taken'].agg(['min', 'max'])\n",
    "summary_update = data['last_update'].agg(['min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eaf075c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload Dates Summary: min   NaN\n",
      "max   NaN\n",
      "Name: date_upload, dtype: float64\n",
      "Taken Dates Summary: min   1825-01-01 00:00:00\n",
      "max   2099-12-27 18:00:11\n",
      "Name: date_taken, dtype: datetime64[ns]\n",
      "Update Dates Summary: min   1970-01-01 00:00:00\n",
      "max   2024-04-23 14:06:00\n",
      "Name: last_update, dtype: datetime64[ns]\n",
      "\n",
      "Calculated Time Intervals:\n",
      "       upload_to_taken        last_update_to_now\n",
      "0                  NaT 4116 days 11:36:28.293254\n",
      "1                  NaT 4116 days 11:36:28.293254\n",
      "2                  NaT 4116 days 11:36:29.293254\n",
      "3                  NaT 4116 days 11:36:29.293254\n",
      "4                  NaT 4116 days 11:36:29.293254\n",
      "...                ...                       ...\n",
      "677725             NaT                       NaT\n",
      "677726             NaT                       NaT\n",
      "677727             NaT                       NaT\n",
      "677728             NaT                       NaT\n",
      "677729             NaT                       NaT\n",
      "\n",
      "[677730 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate time intervals\n",
    "data['upload_to_taken'] = data.apply(\n",
    "    lambda row: row['date_taken'] - row['date_upload'] if pd.notna(row['date_taken']) and pd.notna(row['date_upload']) else pd.NaT,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "data['last_update_to_now'] = data.apply(\n",
    "    lambda row: pd.Timestamp('now') - row['last_update'] if pd.notna(row['last_update']) else pd.NaT,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Output summary statistics\n",
    "print(\"Upload Dates Summary:\", summary_upload)\n",
    "print(\"Taken Dates Summary:\", summary_taken)\n",
    "print(\"Update Dates Summary:\", summary_update)\n",
    "print(\"\\nCalculated Time Intervals:\")\n",
    "print(data[['upload_to_taken', 'last_update_to_now']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c3161f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of data with descriptions: 91.91%\n"
     ]
    }
   ],
   "source": [
    "# Determine non-empty and non-null descriptions\n",
    "non_empty_descriptions = data['title'].apply(lambda x: isinstance(x, str) and x.strip() != '')\n",
    "\n",
    "# Calculate the percentage of non-empty/non-null descriptions\n",
    "percentage_with_descriptions = (non_empty_descriptions.sum() / len(data) * 100)\n",
    "\n",
    "print(f\"Percentage of data with descriptions: {percentage_with_descriptions:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ba04142",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only supported for TrueType fonts",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m         counts_line \u001b[38;5;241m=\u001b[39m wc\u001b[38;5;241m.\u001b[39mprocess_text(line)\n\u001b[0;32m     11\u001b[0m         counts_all\u001b[38;5;241m.\u001b[39mupdate(counts_line)\n\u001b[1;32m---> 13\u001b[0m \u001b[43mwc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_frequencies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcounts_all\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m wc\u001b[38;5;241m.\u001b[39mto_file(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwc.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\wordcloud\\wordcloud.py:453\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    451\u001b[0m     font_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 453\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_frequencies\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfrequencies\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mmax_font_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m     \u001b[38;5;66;03m# find font sizes\u001b[39;00m\n\u001b[0;32m    456\u001b[0m     sizes \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout_]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\wordcloud\\wordcloud.py:511\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    508\u001b[0m transposed_font \u001b[38;5;241m=\u001b[39m ImageFont\u001b[38;5;241m.\u001b[39mTransposedFont(\n\u001b[0;32m    509\u001b[0m     font, orientation\u001b[38;5;241m=\u001b[39morientation)\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# get size of resulting text\u001b[39;00m\n\u001b[1;32m--> 511\u001b[0m box_size \u001b[38;5;241m=\u001b[39m \u001b[43mdraw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtextbbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfont\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransposed_font\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manchor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# find possible places using integral image:\u001b[39;00m\n\u001b[0;32m    513\u001b[0m result \u001b[38;5;241m=\u001b[39m occupancy\u001b[38;5;241m.\u001b[39msample_position(box_size[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmargin,\n\u001b[0;32m    514\u001b[0m                                    box_size[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmargin,\n\u001b[0;32m    515\u001b[0m                                    random_state)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\PIL\\ImageDraw.py:671\u001b[0m, in \u001b[0;36mImageDraw.textbbox\u001b[1;34m(self, xy, text, font, anchor, spacing, align, direction, features, language, stroke_width, embedded_color)\u001b[0m\n\u001b[0;32m    669\u001b[0m     font \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetfont()\n\u001b[0;32m    670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(font, ImageFont\u001b[38;5;241m.\u001b[39mFreeTypeFont):\n\u001b[1;32m--> 671\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly supported for TrueType fonts\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    672\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGBA\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m embedded_color \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfontmode\n\u001b[0;32m    673\u001b[0m bbox \u001b[38;5;241m=\u001b[39m font\u001b[38;5;241m.\u001b[39mgetbbox(\n\u001b[0;32m    674\u001b[0m     text, mode, direction, features, language, stroke_width, anchor\n\u001b[0;32m    675\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: Only supported for TrueType fonts"
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "\n",
    "wc = WordCloud()\n",
    "\n",
    "counts_all = Counter()\n",
    "\n",
    "with open('example.txt', 'r') as f:\n",
    "    for line in f:  # Here you can also use the Cursor\n",
    "        counts_line = wc.process_text(line)\n",
    "        counts_all.update(counts_line)\n",
    "\n",
    "wc.generate_from_frequencies(counts_all)\n",
    "wc.to_file('wc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af168950",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
